DIR_NAME: g:\Workspaces\Anaconda_ws\Semantic_Denoising_MVS\scripts 

DEVICE: cuda? True

Graph params:
(pLambda,pAlpha,pCigma_int,pCigma_spa,pB,pK,pQ): 
(20,15,0.07,3,9,20,3)

MatI: 
tensor([[ 63.,  62.,  64.,  ..., 114., 122., 115.],
        [ 65.,  63.,  67.,  ..., 115., 125., 119.],
        [ 62.,  73.,  67.,  ..., 116., 119., 116.],
        ...,
        [ 83.,  66.,  77.,  ...,  85.,  80.,  81.],
        [ 87.,  55.,  82.,  ...,  73.,  78.,  74.],
        [ 71.,  69.,  73.,  ...,  72.,  85.,  88.]])
MatC: 
tensor([[0.9529, 0.9686, 0.9804,  ..., 0.9882, 0.9961, 0.9961],
        [0.9137, 0.9451, 0.9490,  ..., 0.9882, 0.9961, 0.9961],
        [0.8510, 0.8549, 0.9098,  ..., 0.9922, 0.9922, 0.9922],
        ...,
        [0.9490, 0.8941, 0.9098,  ..., 0.9804, 0.9804, 0.9843],
        [0.9490, 0.9176, 0.9216,  ..., 0.9804, 0.9804, 0.9804],
        [0.9373, 0.9216, 0.9333,  ..., 0.9725, 0.9804, 0.9843]])
debug:
MatD.shape: torch.Size([59, 98]) 
has nan? False 
MatD: 
tensor([[0.0159, 0.0161, 0.0156,  ..., 0.0088, 0.0082, 0.0087],
        [0.0154, 0.0159, 0.0149,  ..., 0.0087, 0.0080, 0.0084],
        [0.0161, 0.0137, 0.0149,  ..., 0.0086, 0.0084, 0.0086],
        ...,
        [0.0120, 0.0152, 0.0130,  ..., 0.0118, 0.0125, 0.0123],
        [0.0115, 0.0182, 0.0122,  ..., 0.0137, 0.0128, 0.0135],
        [0.0141, 0.0145, 0.0137,  ..., 0.0139, 0.0118, 0.0114]]) 

MatU.shape: torch.Size([59, 98, 2]) 
has nan? False 
MatUx: 
tensor([[ 0.0003, -0.0005,  0.0002,  ..., -0.0006,  0.0005,  0.0005],
        [ 0.0005, -0.0009,  0.0005,  ..., -0.0007,  0.0004,  0.0004],
        [-0.0024,  0.0012, -0.0004,  ..., -0.0002,  0.0002,  0.0002],
        ...,
        [ 0.0031, -0.0022,  0.0009,  ...,  0.0007, -0.0002, -0.0002],
        [ 0.0067, -0.0060,  0.0017,  ..., -0.0009,  0.0007,  0.0007],
        [ 0.0004, -0.0008,  0.0004,  ..., -0.0021, -0.0004, -0.0004]]) 

Optimize & Adam params:
(n_iter,lr,betas,eps):
(20,0.0005,(0.9, 0.999),1e-08)










test_counter in loss_omega_mat(): 578
test_counter in loss_omega_mat(): 1156
test_counter in loss_omega_mat(): 1734
test_counter in loss_omega_mat(): 2312
test_counter in loss_omega_mat(): 2890
test_counter in loss_omega_mat(): 3468
test_counter in loss_omega_mat(): 4046
mat_omega_topk has nan? False 

mat_duij has nan? False 

mat_uij has nan? False 

mat_omega_topk: 
tensor([[[0.9456, 0.9453, 0.9450,  ..., 0.6405, 0.6065, 0.6065],
         [0.4517, 0.4407, 0.4255,  ..., 0.2921, 0.2921, 0.2918],
         [0.4407, 0.4254, 0.4209,  ..., 0.2917, 0.2887, 0.2750],
         ...,
         [0.9459, 0.9459, 0.9459,  ..., 0.7573, 0.7572, 0.7571],
         [0.9459, 0.9459, 0.9458,  ..., 0.7572, 0.7570, 0.7568],
         [0.9459, 0.9459, 0.9457,  ..., 0.7569, 0.7568, 0.7564]],

        [[0.9456, 0.9455, 0.9454,  ..., 0.6408, 0.6408, 0.6407],
         [0.9455, 0.9453, 0.9452,  ..., 0.6400, 0.6065, 0.6065],
         [0.9453, 0.9452, 0.9452,  ..., 0.6399, 0.6065, 0.6065],
         ...,
         [0.9459, 0.9459, 0.9459,  ..., 0.7573, 0.7573, 0.7572],
         [0.9459, 0.9459, 0.9458,  ..., 0.7573, 0.7571, 0.7571],
         [0.9459, 0.9459, 0.9457,  ..., 0.7572, 0.7571, 0.7569]],

        [[0.9455, 0.9455, 0.9454,  ..., 0.7569, 0.7569, 0.6408],
         [0.9455, 0.9453, 0.9453,  ..., 0.7562, 0.6407, 0.6407],
         [0.9453, 0.9453, 0.9452,  ..., 0.6408, 0.6407, 0.6406],
         ...,
         [0.9459, 0.9459, 0.9459,  ..., 0.7573, 0.7573, 0.7572],
         [0.9459, 0.9459, 0.9458,  ..., 0.7573, 0.7572, 0.7571],
         [0.9459, 0.9459, 0.9457,  ..., 0.7572, 0.7571, 0.7571]],

        ...,

        [[0.9458, 0.9458, 0.9458,  ..., 0.7571, 0.7569, 0.7565],
         [0.9459, 0.9458, 0.9458,  ..., 0.7573, 0.7564, 0.7490],
         [0.9459, 0.9458, 0.9452,  ..., 0.7571, 0.7449, 0.7447],
         ...,
         [0.9459, 0.9459, 0.9453,  ..., 0.7567, 0.7565, 0.7564],
         [0.9459, 0.9459, 0.9452,  ..., 0.7566, 0.7564, 0.7563],
         [0.9459, 0.9457, 0.9451,  ..., 0.7564, 0.7564, 0.7562]],

        [[0.9458, 0.9458, 0.9458,  ..., 0.7569, 0.7565, 0.7560],
         [0.9458, 0.9458, 0.9458,  ..., 0.7543, 0.7515, 0.7455],
         [0.9454, 0.9452, 0.9452,  ..., 0.7506, 0.7455, 0.7405],
         ...,
         [0.9458, 0.9455, 0.9454,  ..., 0.7565, 0.7564, 0.7563],
         [0.9455, 0.9455, 0.9453,  ..., 0.7565, 0.7564, 0.7564],
         [0.9455, 0.9454, 0.9454,  ..., 0.7564, 0.7563, 0.7562]],

        [[0.9458, 0.9458, 0.9458,  ..., 0.7569, 0.7565, 0.7539],
         [0.9458, 0.9458, 0.9458,  ..., 0.7520, 0.7500, 0.7431],
         [0.9452, 0.9449, 0.9444,  ..., 0.7475, 0.7442, 0.7371],
         ...,
         [0.9457, 0.9455, 0.9454,  ..., 0.7566, 0.7566, 0.7558],
         [0.9455, 0.9454, 0.9453,  ..., 0.7567, 0.7565, 0.7562],
         [0.9454, 0.9454, 0.9452,  ..., 0.7566, 0.7565, 0.7563]]],
       grad_fn=<SliceBackward>) 

mat_duij: 
tensor([[[1.5306e-06, 4.0484e-08, 3.8611e-07,  ..., 1.6194e-07,
          2.7048e-06, 1.0837e-06],
         [6.7664e-07, 5.9629e-07, 1.1162e-06,  ..., 2.2855e-06,
          1.0239e-06, 3.6436e-07],
         [4.1929e-06, 1.8933e-07, 1.6268e-06,  ..., 1.7672e-05,
          1.1506e-05, 1.2208e-05],
         ...,
         [1.6670e-07, 9.5653e-08, 9.8029e-09,  ..., 4.4213e-08,
          6.6680e-07, 5.8263e-08],
         [1.9661e-07, 9.5653e-08, 1.9661e-07,  ..., 4.6043e-07,
          3.0338e-07, 1.7094e-07],
         [1.6773e-06, 2.6592e-07, 2.6592e-07,  ..., 2.6592e-07,
          7.5769e-06, 1.2975e-06]],

        [[2.8325e-07, 1.7654e-07, 1.7654e-07,  ..., 2.0375e-06,
          2.1904e-06, 2.9109e-06],
         [1.7654e-07, 4.1929e-06, 4.1929e-06,  ..., 9.3287e-06,
          2.3838e-05, 1.5889e-06],
         [1.7654e-07, 1.3507e-05, 1.7654e-07,  ..., 1.7102e-05,
          1.9209e-05, 4.6486e-05],
         ...,
         [1.6670e-07, 2.5735e-07, 1.0000e-20,  ..., 6.6680e-07,
          8.3830e-07, 6.6680e-07],
         [1.6670e-07, 1.6670e-07, 1.6670e-07,  ..., 7.2539e-07,
          6.6680e-07, 9.6858e-08],
         [4.0742e-07, 1.3124e-06, 9.0385e-07,  ..., 1.0699e-06,
          2.9083e-07, 5.5747e-10]],

        [[1.9859e-07, 1.0000e-20, 1.0000e-20,  ..., 1.7654e-07,
          4.1929e-06, 2.3963e-06],
         [3.8611e-07, 3.8611e-07, 1.7654e-07,  ..., 2.1381e-06,
          4.2425e-06, 2.7653e-06],
         [1.5049e-06, 3.3422e-06, 1.0146e-06,  ..., 3.3566e-06,
          8.2579e-06, 2.4823e-06],
         ...,
         [1.6670e-07, 9.4222e-09, 2.5538e-07,  ..., 1.0103e-06,
          3.6291e-07, 3.7277e-07],
         [6.6680e-07, 5.4362e-07, 1.0825e-07,  ..., 2.4146e-06,
          6.9943e-07, 7.1822e-06],
         [9.0016e-07, 1.3535e-06, 9.0016e-07,  ..., 6.8514e-06,
          2.4383e-06, 4.3517e-06]],

        ...,

        [[1.5747e-07, 4.0484e-08, 4.0485e-08,  ..., 9.7911e-07,
          4.0485e-08, 1.6194e-07],
         [3.5764e-07, 3.2603e-07, 3.2603e-07,  ..., 3.0471e-06,
          1.9090e-06, 2.3852e-06],
         [1.4890e-07, 1.6194e-07, 3.4467e-07,  ..., 6.2140e-07,
          8.3810e-05, 9.9396e-06],
         ...,
         [2.1588e-08, 2.1588e-08, 1.5951e-06,  ..., 6.6560e-07,
          5.8572e-07, 1.0033e-06],
         [3.3333e-07, 1.8526e-07, 2.4237e-06,  ..., 7.8320e-08,
          3.9491e-06, 6.0170e-07],
         [2.2668e-08, 8.8498e-08, 3.7071e-06,  ..., 4.9573e-06,
          2.5146e-06, 4.4657e-06]],

        [[1.4091e-07, 1.3674e-07, 1.4091e-07,  ..., 1.8350e-06,
          2.5155e-10, 1.8782e-06],
         [4.0485e-08, 2.3852e-06, 1.3041e-06,  ..., 1.2908e-06,
          3.4103e-08, 1.5350e-06],
         [3.1941e-07, 1.6667e-07, 1.6194e-07,  ..., 1.4457e-06,
          6.6375e-06, 1.3566e-05],
         ...,
         [3.5399e-07, 3.3753e-07, 3.3753e-07,  ..., 2.4492e-06,
          5.1727e-06, 3.8973e-06],
         [2.8112e-06, 6.5969e-07, 6.5969e-07,  ..., 3.6938e-06,
          2.0413e-06, 2.4941e-06],
         [2.0518e-06, 1.6852e-07, 1.6852e-07,  ..., 1.1838e-05,
          8.9742e-09, 3.4217e-06]],

        [[4.0484e-08, 1.5307e-07, 4.0485e-08,  ..., 6.7664e-07,
          4.0022e-07, 1.4854e-07],
         [4.2865e-08, 2.6486e-08, 3.1247e-11,  ..., 1.0357e-06,
          3.4010e-11, 3.1382e-06],
         [3.8686e-06, 1.6667e-07, 4.7259e-06,  ..., 1.1962e-04,
          5.8869e-07, 1.7361e-05],
         ...,
         [1.6539e-07, 3.0779e-08, 2.6495e-07,  ..., 6.0406e-06,
          2.3641e-07, 2.2810e-06],
         [2.1612e-06, 1.0115e-06, 9.3442e-06,  ..., 2.5958e-05,
          1.3193e-05, 1.4419e-05],
         [9.9629e-06, 2.4096e-06, 6.2709e-07,  ..., 1.2029e-06,
          9.2564e-08, 2.1429e-07]]], grad_fn=<CopySlices>) 

mat_uij: 
tensor([[[1.4447e-03, 1.0451e-03, 9.4000e-04,  ..., 1.3741e-03,
          2.2025e-04, 2.8949e-04],
         [6.2341e-04, 1.0789e-03, 2.8710e-03,  ..., 2.8455e-04,
          4.0957e-04, 1.6510e-03],
         [2.9354e-03, 1.7905e-03, 3.0949e-03,  ..., 1.3044e-03,
          3.1642e-04, 2.1427e-03],
         ...,
         [1.4002e-04, 3.2474e-04, 3.0928e-04,  ..., 8.6235e-04,
          5.7877e-04, 1.0050e-03],
         [1.1545e-03, 1.6672e-04, 8.5170e-04,  ..., 1.0256e-03,
          9.5909e-04, 1.3004e-03],
         [1.1545e-03, 5.4969e-04, 1.6475e-03,  ..., 1.4687e-03,
          1.3399e-03, 1.8780e-03]],

        [[1.6916e-03, 1.6275e-03, 4.2017e-04,  ..., 1.5583e-03,
          9.6858e-04, 1.4184e-03],
         [1.6275e-03, 1.9322e-03, 3.6392e-03,  ..., 2.7127e-03,
          5.4322e-04, 6.7511e-04],
         [3.3638e-03, 3.6392e-03, 2.0000e-03,  ..., 3.0134e-03,
          5.7905e-04, 7.1304e-04],
         ...,
         [9.7068e-05, 1.4002e-04, 4.0829e-04,  ..., 5.8048e-04,
          3.2474e-04, 5.8928e-04],
         [8.1658e-04, 8.9497e-04, 8.5170e-04,  ..., 1.0329e-03,
          6.8010e-04, 1.2181e-03],
         [3.1803e-04, 8.9497e-04, 1.6475e-03,  ..., 4.7689e-04,
          1.0415e-03, 9.5993e-04]],

        [[1.3390e-03, 6.2138e-04, 7.5010e-04,  ..., 1.0409e-03,
          2.6156e-03, 2.0440e-03],
         [6.2138e-04, 9.0859e-04, 1.9322e-03,  ..., 9.6626e-04,
          8.1964e-04, 1.4872e-03],
         [1.1100e-03, 3.3638e-03, 4.4393e-04,  ..., 1.6498e-03,
          1.4442e-03, 1.0255e-03],
         ...,
         [9.7068e-05, 4.1967e-04, 3.2116e-04,  ..., 5.2944e-04,
          8.8985e-04, 1.9192e-03],
         [3.2116e-04, 4.7709e-04, 8.4281e-04,  ..., 8.2922e-04,
          1.1643e-03, 1.2898e-03],
         [1.6177e-04, 4.7709e-04, 8.4218e-04,  ..., 2.7444e-04,
          1.3063e-03, 1.2212e-03]],

        ...,

        [[5.9803e-04, 6.0541e-04, 5.7102e-04,  ..., 1.2877e-03,
          5.6933e-04, 4.5514e-04],
         [1.2345e-03, 9.9077e-04, 1.6588e-03,  ..., 9.9859e-04,
          2.4975e-03, 9.9547e-03],
         [2.7692e-04, 9.9077e-04, 1.8476e-04,  ..., 7.0254e-04,
          1.0741e-02, 1.9116e-03],
         ...,
         [4.5480e-04, 3.3018e-04, 1.4175e-03,  ..., 1.9264e-03,
          5.5091e-04, 1.4518e-04],
         [4.5480e-04, 5.9926e-04, 1.9996e-03,  ..., 1.6342e-03,
          4.4536e-04, 4.8397e-04],
         [5.9926e-04, 9.5845e-04, 1.6480e-03,  ..., 4.2364e-04,
          4.6592e-04, 2.1037e-04]],

        [[9.6886e-04, 5.7102e-04, 1.5466e-03,  ..., 5.4730e-04,
          1.4170e-03, 2.7519e-03],
         [5.1885e-04, 1.6588e-03, 1.5466e-03,  ..., 1.7099e-03,
          7.9408e-04, 9.3702e-04],
         [1.0392e-03, 2.3841e-03, 1.8476e-04,  ..., 9.5891e-03,
          5.1530e-03, 4.1035e-03],
         ...,
         [8.7857e-04, 1.3957e-03, 1.2949e-03,  ..., 1.1574e-03,
          1.2609e-03, 1.1344e-03],
         [1.3957e-03, 2.4663e-03, 3.0406e-03,  ..., 2.2475e-03,
          5.8121e-04, 6.0875e-04],
         [2.4663e-03, 2.6075e-03, 1.2366e-03,  ..., 2.4182e-03,
          8.6151e-04, 2.3963e-03]],

        [[6.2921e-04, 9.6886e-04, 2.8892e-04,  ..., 9.0827e-04,
          1.8388e-03, 2.1358e-03],
         [4.8241e-04, 5.1885e-04, 2.8892e-04,  ..., 5.2875e-03,
          9.0808e-03, 4.6511e-03],
         [2.3841e-03, 1.7771e-03, 4.0825e-04,  ..., 1.2952e-02,
          2.1800e-03, 3.9513e-03],
         ...,
         [4.6683e-04, 2.9728e-03, 1.2949e-03,  ..., 3.3386e-05,
          1.6342e-03, 1.2801e-03],
         [2.9728e-03, 3.1963e-03, 3.0406e-03,  ..., 1.9264e-03,
          1.7187e-03, 6.6912e-04],
         [3.1963e-03, 2.6075e-03, 1.4376e-03,  ..., 4.9722e-04,
          3.4729e-03, 2.4031e-03]]], grad_fn=<CopySlices>) 

loss = loss1 + lambda*loss2
loss1:0.0 loss2:2117.10205078125


loss.item(): 42342.0390625


Finish constructing loss, calculating backward() ... 
